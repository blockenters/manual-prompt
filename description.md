# 상용 RAG 시스템 구축? 이 세 가지만 알면 됩니다!
이 세가지를 모르면, 어디가서 RAG 해봤다고 말하지 마세요~


## 주장
저는 현업 SW개발자이며, 기업 및 취준생 대상으로 강의도 하고 있습니다. 간단히 3가지만 가지고도, 여러분들이 성능 좋은 RAG를 만들어서 회사의 프로젝트나 포트폴리오로 사용할 수 있게 해드리겠습니다. 취준생 같은 경우에는 면접에서 남들과 확실한 차별성을 둘 수 있습니다. 완전 오픈소스로 구성하는 방법과 유료를 섞은 방법, 둘다 비교해서 보여드리겠습니다. 코드는 설명란 링크에 있습니다.

## 이유
일단 말씀드리자면, 실제 사용자들이 쓸만한 상용 서비스를 만들려면 몇 가지 중요한 선택이 필요합니다.

1. (화면 텍스트로)**임베딩 모델**: 문서와 질문을 벡터로 변환하는 임베딩 모델에 따라 검색 정확도가 완전히 달라집니다. 특히 한국어 문서라면 모델 선택이 더 중요합니다. 실제로 엄청난 차이가 났습니다.

2. (화면 텍스트로)**chunk_size**: 문서를 너무 작게 쪼개면 맥락이 다 날아가버리고, 너무 크게 나누면 관련 없는 정보까지 딸려와서 정확도가 떨어집니다. 청크 사이즈 하나로 답변 품질이 바뀝니다.

3. (화면 텍스트로)**chunk_overlap**: 청크 간에 얼마나 겹치게 할지도 중요합니다. 너무 적게 겹치면 맥락이 끊기고, 너무 많이 겹치면 중복 정보 때문에 효율이 떨어지거든요.

이 세 가지를 어떻게 조합하느냐에 따라서, 같은 문서 같은 질문에도 전혀 다른 결과가 나옵니다. 다음으로 제가 사용한 방법을 알려 드릴테니, 여러분도 여러가지 테스트를 통해 성능좋은 RAG를 만드시기 바랍니다.  

## 사례
제가 실제로 PDF 문서 기반 질의응답 시스템 개발하면서 테스트한 결과를 공유해 드립니다:

### 임베딩 모델 비교
우선 두 가지 임베딩 모델을 비교했습니다. 첫 번째는 Hugging Face의 (화면텍스트로)'sentence-transformers/all-MiniLM-L6-v2' 모델로, 오픈소스이며 무료로 사용할 수 있는 장점이 있습니다. 두 번째는 OpenAI의 'text-embedding-3-small' 모델로, API 호출 비용이 들지만 성능이 우수하다고 알려져 있고, 한국어 처리에 강점이 있습니다.

### 청킹 및 오버랩 설정
청킹 전략도 두 가지로 테스트했습니다. 첫 번째는 작은 청크 사이즈인 256토큰, 50토큰 오버랩을 사용한 방법입니다. 두 번째는 큰 청크 사이즈(512자)와 동일한 50자 오버랩을 사용했습니다. 청크 사이즈는 한 번에 처리하는 텍스트 단위의 크기를, 오버랩은 각 청크가 서로 얼마나 겹치는지를 의미합니다.
`text-embedding-3-small` 
테스트 결과, OpenAI의 모델에 청킹 사이즈 512, 오버랩 50의 조합이 압도적으로 좋았습니다. 같은 질문을 던졌는데도 PDF 원본과 비교했을 때 정확도와 맥락 이해도가 완전히 달랐습니다.

같은 오픈소스 젬마 투 LLM인데도, 임베딩 모델 하나 바꿨을 뿐인데 결과가 천지차이였습니다.

## 제안
여러분도 이제 상용 수준의 RAG 시스템을 만들고 싶으시다면, 임베딩 모델, 청킹 사이즈, 청크 오버랩 뿐만 아니라, 더 나아가서 탑 케이, 유사도 임계값 similarity_cutoff 도 바꿔가면서 테스트 해보세요. 